{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Walmart Sales Forecasting - Exploratory Data Analysis & Feature Importance\n",
    "# ---------------------------------------------------------------------------\n",
    "# This notebook explores the processed Walmart sales dataset and visualizes \n",
    "# patterns, seasonality, and model feature importance.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# %%\n",
    "# Paths\n",
    "DATA_DIR = Path(\"data/processed\")\n",
    "MODEL_DIR = Path(\"models\")\n",
    "\n",
    "# Load processed data\n",
    "train = pd.read_parquet(DATA_DIR / \"train.parquet\")\n",
    "val = pd.read_parquet(DATA_DIR / \"val.parquet\")\n",
    "\n",
    "print(f\"Train shape: {train.shape}, Val shape: {val.shape}\")\n",
    "train.head()\n",
    "\n",
    "# %%\n",
    "# Basic statistics\n",
    "train.describe(include='all').T\n",
    "\n",
    "# %%\n",
    "# Check date range and unique stores/departments\n",
    "print(f\"Date range: {train['Date'].min()} to {train['Date'].max()}\")\n",
    "print(f\"Stores: {train['Store'].nunique()}, Departments: {train['Dept'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Aggregate weekly sales trends over time\n",
    "agg_sales = train.groupby(\"Date\")[\"Weekly_Sales\"].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(agg_sales[\"Date\"], agg_sales[\"Weekly_Sales\"], color=\"tab:blue\")\n",
    "plt.title(\"Total Weekly Sales Over Time\", fontsize=14)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Total Weekly Sales\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Average sales by month and week of year\n",
    "train[\"month\"] = train[\"Date\"].dt.month\n",
    "train[\"weekofyear\"] = train[\"Date\"].dt.isocalendar().week.astype(int)\n",
    "\n",
    "monthly_sales = train.groupby(\"month\")[\"Weekly_Sales\"].mean()\n",
    "plt.figure(figsize=(10,5))\n",
    "monthly_sales.plot(kind=\"bar\", color=\"tab:green\")\n",
    "plt.title(\"Average Weekly Sales by Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Avg Weekly Sales\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Average sales by store (top 10)\n",
    "top_stores = (\n",
    "    train.groupby(\"Store\")[\"Weekly_Sales\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=top_stores.index, y=top_stores.values, palette=\"Blues_d\")\n",
    "plt.title(\"Top 10 Stores by Average Weekly Sales\")\n",
    "plt.xlabel(\"Store\")\n",
    "plt.ylabel(\"Avg Weekly Sales\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Holiday vs Non-holiday comparison\n",
    "holiday_sales = train.groupby(\"IsHoliday\")[\"Weekly_Sales\"].mean()\n",
    "sns.barplot(x=holiday_sales.index, y=holiday_sales.values, palette=\"coolwarm\")\n",
    "plt.title(\"Holiday vs Non-Holiday Weekly Sales\")\n",
    "plt.xlabel(\"IsHoliday\")\n",
    "plt.ylabel(\"Average Weekly Sales\")\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Correlation matrix for numeric features\n",
    "num_cols = train.select_dtypes(include=np.number).columns\n",
    "corr = train[num_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Distribution of Weekly Sales\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(train[\"Weekly_Sales\"], bins=50, kde=True)\n",
    "plt.title(\"Distribution of Weekly Sales\")\n",
    "plt.xlabel(\"Weekly Sales\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Load trained LightGBM model and feature list\n",
    "model = joblib.load(MODEL_DIR / \"lgb_model.joblib\")\n",
    "features = joblib.load(MODEL_DIR / \"feature_list.joblib\")\n",
    "\n",
    "# %%\n",
    "# Feature importance visualization\n",
    "importance = model.feature_importance(importance_type=\"gain\")\n",
    "importance_df = pd.DataFrame({\"feature\": features, \"importance\": importance})\n",
    "importance_df = importance_df.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=importance_df.head(15), x=\"importance\", y=\"feature\", palette=\"viridis\")\n",
    "plt.title(\"Top 15 Feature Importances (LightGBM Gain)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Feature importance (split count)\n",
    "split_importance = model.feature_importance(importance_type=\"split\")\n",
    "split_df = pd.DataFrame({\"feature\": features, \"importance\": split_importance}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=split_df.head(15), x=\"importance\", y=\"feature\", palette=\"mako\")\n",
    "plt.title(\"Top 15 Feature Importances (Split Count)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Weekly pattern for a single store/department\n",
    "example = train[(train[\"Store\"] == \"1\") & (train[\"Dept\"] == \"1\")].copy()\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(example[\"Date\"], example[\"Weekly_Sales\"], color=\"tab:orange\")\n",
    "plt.title(\"Example: Store 1 Dept 1 Weekly Sales\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Weekly Sales\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Time vs Lag relationship check\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=\"lag_1\", y=\"Weekly_Sales\", data=train.sample(5000, random_state=42), alpha=0.3)\n",
    "plt.title(\"Weekly Sales vs Lag_1 Feature\")\n",
    "plt.xlabel(\"Previous Week Sales (lag_1)\")\n",
    "plt.ylabel(\"Current Week Sales\")\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Save correlation & feature importance data for reporting\n",
    "importance_df.to_csv(MODEL_DIR / \"feature_importance.csv\", index=False)\n",
    "corr.to_csv(MODEL_DIR / \"correlation_matrix.csv\")\n",
    "print(\"Saved feature_importance.csv and correlation_matrix.csv in models/\")\n",
    "\n",
    "# %%\n",
    "print(\"EDA and Feature Importance analysis completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
